{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Feature analysis\n",
    "\n",
    "Check that an older version of numpy is being used by the system since numpy versions past 2.00 cause mlxtend due to some NPN metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:43.861285Z",
     "iopub.status.busy": "2024-11-12T11:27:43.858473Z",
     "iopub.status.idle": "2024-11-12T11:27:43.951035Z",
     "shell.execute_reply": "2024-11-12T11:27:43.951564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load the dataset from https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized saved as a csv file \"CommViolPredUnnormalizedData.csv\". The dataset has 147 features of which; 125 predictive, 4 non-predictive, 18 potential goal features. The goal feature to be taken is the assultPerPop feature which describes the number of assaults per 100,000 population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:43.954162Z",
     "iopub.status.busy": "2024-11-12T11:27:43.953413Z",
     "iopub.status.idle": "2024-11-12T11:27:44.106703Z",
     "shell.execute_reply": "2024-11-12T11:27:44.106451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Raw Shape: (2215, 148)\n",
      "Dataset Headers: ['Unnamed: 0', 'communityname', 'state', 'countyCode', 'communityCode', 'fold', 'population', 'householdsize', 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29', 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf', 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap', 'blackPerCap', 'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov', 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu', 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr', 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par', 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumKidsBornNeverMar', 'PctKidsBornNeverMar', 'NumImmig', 'PctImmigRecent', 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8', 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup', 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous', 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded', 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal', 'OwnOccHiQuart', 'OwnOccQrange', 'RentLowQ', 'RentMedian', 'RentHighQ', 'RentQrange', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc', 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85', 'PctSameCity85', 'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'LandArea', 'PopDens', 'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'murders', 'murdPerPop', 'rapes', 'rapesPerPop', 'robberies', 'robbbPerPop', 'assaults', 'assaultPerPop', 'burglaries', 'burglPerPop', 'larcenies', 'larcPerPop', 'autoTheft', 'autoTheftPerPop', 'arsons', 'arsonsPerPop', 'ViolentCrimesPerPop', 'nonViolPerPop']\n"
     ]
    }
   ],
   "source": [
    "# Importing pandas for loading the dataset and data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Load Dataset\n",
    "dataset = pd.read_csv(\"assignment-1/CommViolPredUnnormalizedData.csv\", header=0)\n",
    "\n",
    "# Get the shape of the dataset\n",
    "print(\"Dataset Raw Shape:\", dataset.shape)\n",
    "\n",
    "# Print the headers to inspect them\n",
    "print(\"Dataset Headers:\", dataset.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data cleaning, missing data and normalization\n",
    "### Drop Non-Predictive and Goal Columns\n",
    "Remove the columns that are not predictive or are potential goals that arent the target column. The working dataset should only contain predictive features and the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.111429Z",
     "iopub.status.busy": "2024-11-12T11:27:44.110814Z",
     "iopub.status.idle": "2024-11-12T11:27:44.113273Z",
     "shell.execute_reply": "2024-11-12T11:27:44.113498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape after dropping columns: (2215, 126)\n"
     ]
    }
   ],
   "source": [
    "# Define a list of non-predictive headers\n",
    "non_predicitive_headers = ['communityname', 'countyCode', 'communityCode', 'fold']\n",
    "\n",
    "# Define a list of potential goal headers\n",
    "goal_headers = ['murders', 'murdPerPop', 'rapes', 'rapesPerPop', 'robberies', 'robbbPerPop', 'assaults', 'burglaries', 'burglPerPop', 'larcenies', 'larcPerPop', 'autoTheft', 'autoTheftPerPop', 'arsons', 'arsonsPerPop', 'ViolentCrimesPerPop', 'nonViolPerPop']\n",
    "\n",
    "# Combine both lists of headers and also drop the index column from the csv format\n",
    "headers_to_drop = ['Unnamed: 0'] + non_predicitive_headers + goal_headers\n",
    "\n",
    "# Check if the headers exist in the dataset if not dont add them to the drop list as they will throw an error\n",
    "headers_to_drop = [header for header in headers_to_drop if header in dataset.columns]\n",
    "\n",
    "# Drop the columns\n",
    "dataset.drop(columns=headers_to_drop, inplace=True)\n",
    "\n",
    "# Print the shape of the dataset after dropping columns\n",
    "print(\"Dataset Shape after dropping columns:\", dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handeling of Non-Numeric Features\n",
    "\n",
    "The non-numeric features can not be processed noramally through mathematical operations that we require, such as normalization, so we need to convert them to a numeric format. For the state we can use a dictionary to map each unique state to a unique numeric value. For the other non-numeric features we can use one-hot encoding to convert them to a numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.117223Z",
     "iopub.status.busy": "2024-11-12T11:27:44.116797Z",
     "iopub.status.idle": "2024-11-12T11:27:44.140387Z",
     "shell.execute_reply": "2024-11-12T11:27:44.140137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Numeric Features: ['state', 'OtherPerCap', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps', 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr', 'LemasGangUnitDeploy', 'PolicBudgPerPop', 'assaultPerPop']\n",
      "All Features are Numeric: True\n"
     ]
    }
   ],
   "source": [
    "# Replace missing values indicated by '?' with np.nan values\n",
    "dataset = dataset.replace('?', np.nan)\n",
    "# Note this is done here to avoid errors when converting to numeric but will also be needed for imputation\n",
    "\n",
    "# Print the non-numeric features\n",
    "print(\"Non-Numeric Features:\", dataset.select_dtypes(exclude='number').columns.tolist())\n",
    "\n",
    "# Get the unique instances of the state column\n",
    "states = dataset['state'].unique()\n",
    "\n",
    "# Create a dictionary for each unique state and its corresponding numeric value\n",
    "state_dict = {state: i for i, state in enumerate(states)}\n",
    "\n",
    "# Map the state column to the dictionary\n",
    "dataset['state'] = dataset['state'].map(state_dict)\n",
    "\n",
    "# Convert the dataset to a numeric format\n",
    "dataset = dataset.apply(pd.to_numeric)\n",
    "\n",
    "# Check if all features are numeric\n",
    "print(\"All Features are Numeric:\", dataset.select_dtypes(exclude='number').empty)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handeling Missing Values \n",
    "\n",
    "1. Remove rows/columns with missing values. It is a simple implementation but can lead to a lot of data loss if there are many missing data occurances.\n",
    "\n",
    "2. Foward or Backward Filling is the method of using previous or next column values (respectively). It is typicaly useful for sequential data.\n",
    "\n",
    "3. Imputation is the filling of data using statistical methods such as the mean, median or mode. Simple to implement without loss of data. However, may cause biases if the data is not randomly missing.\n",
    "\n",
    "4. Specified Algorthimns in the machine learning algorithm can handle the case of missing values. Being specific to the algorithmn can come as a advantage and a constraint.\n",
    "\n",
    "\n",
    "**Imputation** was chosen as the majority of missing values were numeric and the mean strategy is simply and effective for such values.\n",
    "\n",
    "The dataset states that the cuase for the missing values is controversy in some states providing full information on sensitive police data. This resulted in some features having more missing values than informative ones.  Should we completely ommit these columns so, as not to cause baises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.143449Z",
     "iopub.status.busy": "2024-11-12T11:27:44.142983Z",
     "iopub.status.idle": "2024-11-12T11:27:44.483729Z",
     "shell.execute_reply": "2024-11-12T11:27:44.483406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values before imputation:  41198\n",
      "Number of missing values after imputation:  0\n",
      "Dataset Shape after handling missing values: (2215, 126)\n"
     ]
    }
   ],
   "source": [
    "# Import the SimpleImputer class\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Check for missing values in the dataset\n",
    "print(\"Number of missing values before imputation: \", dataset.isnull().sum().sum())\n",
    "\n",
    "# Initialize the SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Apply the imputer using fit_transform on the dataset\n",
    "dataset = pd.DataFrame(imputer.fit_transform(dataset), columns=dataset.columns)\n",
    "\n",
    "# Check for any remaining missing values\n",
    "print(\"Number of missing values after imputation: \", dataset.isnull().sum().sum())\n",
    "\n",
    "# Print the shape of the dataset after imputation\n",
    "print(\"Dataset Shape after handling missing values:\", dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the Dataset\n",
    "\n",
    "Normalization transforms the data to a specific range or distribution, making it easier for machine learning algorithms to process. It ensures that each feature contributes equally to the model, preventing features with larger ranges from dominating the learning process. This is crutial in algorithmns such as the gradient-decent.\n",
    "\n",
    "1. Min-Max Scaling transforms the data to a range [0,1] with a simple formulea. This preserves the relation between data and points on grapichal representations. However, it is sensitive to outlires that may come outside the original min/max.\n",
    "\n",
    "2. Standardization transforms the data to have a mean of 0 and a standard deviation of 1. It is effective for algorithms that assume normally distributed data but is also sensitive to outliers.\n",
    "\n",
    "3. Robust Scaling uses the median and interquartile range for scaling. This fixes the problem of outliers but makes it suffer from data that is not symettrically distributed.\n",
    "\n",
    "4. Max Abs Scaling, scales each feature by its maximum absolute value. Particularly useful for data that is already centered at zero but does not handle outliers well either.\n",
    "\n",
    "Standardization was applied to the dataset. It was chosen as the normalization method due to it being less sensitive to outliers compared to MinMaxScaler. It is usually commonly used for real-world datasets, where the standard deviation is a better measure of spread than the range of values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.487619Z",
     "iopub.status.busy": "2024-11-12T11:27:44.487134Z",
     "iopub.status.idle": "2024-11-12T11:27:44.507378Z",
     "shell.execute_reply": "2024-11-12T11:27:44.507666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>PolicCars</th>\n",
       "      <th>PolicOperBudg</th>\n",
       "      <th>LemasPctPolicOnPatr</th>\n",
       "      <th>LemasGangUnitDeploy</th>\n",
       "      <th>LemasPctOfficDrugUn</th>\n",
       "      <th>PolicBudgPerPop</th>\n",
       "      <th>assaultPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.292815</td>\n",
       "      <td>-0.201091</td>\n",
       "      <td>1.175511</td>\n",
       "      <td>-0.559192</td>\n",
       "      <td>0.475175</td>\n",
       "      <td>0.856235</td>\n",
       "      <td>-0.416149</td>\n",
       "      <td>-0.437364</td>\n",
       "      <td>-1.004000</td>\n",
       "      <td>-0.510125</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190532</td>\n",
       "      <td>-0.331619</td>\n",
       "      <td>1.341436</td>\n",
       "      <td>2.270681e-16</td>\n",
       "      <td>8.583060e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.561128e-16</td>\n",
       "      <td>-0.340751</td>\n",
       "      <td>3.647879e-16</td>\n",
       "      <td>-0.790188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.203014</td>\n",
       "      <td>-0.146622</td>\n",
       "      <td>0.337299</td>\n",
       "      <td>-0.599209</td>\n",
       "      <td>0.706056</td>\n",
       "      <td>0.172105</td>\n",
       "      <td>-0.486762</td>\n",
       "      <td>-0.760544</td>\n",
       "      <td>-1.026653</td>\n",
       "      <td>-0.585510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153190</td>\n",
       "      <td>-0.211125</td>\n",
       "      <td>0.162644</td>\n",
       "      <td>2.270681e-16</td>\n",
       "      <td>8.583060e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.561128e-16</td>\n",
       "      <td>-0.340751</td>\n",
       "      <td>3.647879e-16</td>\n",
       "      <td>-0.631690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.113212</td>\n",
       "      <td>-0.116212</td>\n",
       "      <td>-0.830211</td>\n",
       "      <td>-0.603422</td>\n",
       "      <td>0.630518</td>\n",
       "      <td>0.169869</td>\n",
       "      <td>-0.383928</td>\n",
       "      <td>-0.683070</td>\n",
       "      <td>-0.285567</td>\n",
       "      <td>-0.496724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153190</td>\n",
       "      <td>-0.001038</td>\n",
       "      <td>0.270547</td>\n",
       "      <td>2.270681e-16</td>\n",
       "      <td>8.583060e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.561128e-16</td>\n",
       "      <td>-0.340751</td>\n",
       "      <td>3.647879e-16</td>\n",
       "      <td>-0.776613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.023411</td>\n",
       "      <td>-0.178234</td>\n",
       "      <td>-0.920020</td>\n",
       "      <td>-0.536025</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>-0.485197</td>\n",
       "      <td>-0.497046</td>\n",
       "      <td>-0.419656</td>\n",
       "      <td>-0.395597</td>\n",
       "      <td>-0.299049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202372</td>\n",
       "      <td>0.153398</td>\n",
       "      <td>0.054741</td>\n",
       "      <td>2.270681e-16</td>\n",
       "      <td>8.583060e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.561128e-16</td>\n",
       "      <td>-0.340751</td>\n",
       "      <td>3.647879e-16</td>\n",
       "      <td>-0.428234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.933610</td>\n",
       "      <td>-0.204684</td>\n",
       "      <td>0.157682</td>\n",
       "      <td>-0.618165</td>\n",
       "      <td>0.315569</td>\n",
       "      <td>-0.335403</td>\n",
       "      <td>-0.509386</td>\n",
       "      <td>2.216698</td>\n",
       "      <td>2.084936</td>\n",
       "      <td>2.465049</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144993</td>\n",
       "      <td>-0.639819</td>\n",
       "      <td>-0.541781</td>\n",
       "      <td>2.270681e-16</td>\n",
       "      <td>8.583060e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.561128e-16</td>\n",
       "      <td>-0.340751</td>\n",
       "      <td>3.647879e-16</td>\n",
       "      <td>-0.608593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  population  householdsize  racepctblack  racePctWhite  \\\n",
       "0 -1.292815   -0.201091       1.175511     -0.559192      0.475175   \n",
       "1 -1.203014   -0.146622       0.337299     -0.599209      0.706056   \n",
       "2 -1.113212   -0.116212      -0.830211     -0.603422      0.630518   \n",
       "3 -1.023411   -0.178234      -0.920020     -0.536025      0.814491   \n",
       "4 -0.933610   -0.204684       0.157682     -0.618165      0.315569   \n",
       "\n",
       "   racePctAsian  racePctHisp  agePct12t21  agePct12t29  agePct16t24  ...  \\\n",
       "0      0.856235    -0.416149    -0.437364    -1.004000    -0.510125  ...   \n",
       "1      0.172105    -0.486762    -0.760544    -1.026653    -0.585510  ...   \n",
       "2      0.169869    -0.383928    -0.683070    -0.285567    -0.496724  ...   \n",
       "3     -0.485197    -0.497046    -0.419656    -0.395597    -0.299049  ...   \n",
       "4     -0.335403    -0.509386     2.216698     2.084936     2.465049  ...   \n",
       "\n",
       "   LandArea   PopDens  PctUsePubTrans     PolicCars  PolicOperBudg  \\\n",
       "0 -0.190532 -0.331619        1.341436  2.270681e-16   8.583060e-17   \n",
       "1 -0.153190 -0.211125        0.162644  2.270681e-16   8.583060e-17   \n",
       "2 -0.153190 -0.001038        0.270547  2.270681e-16   8.583060e-17   \n",
       "3 -0.202372  0.153398        0.054741  2.270681e-16   8.583060e-17   \n",
       "4 -0.144993 -0.639819       -0.541781  2.270681e-16   8.583060e-17   \n",
       "\n",
       "   LemasPctPolicOnPatr  LemasGangUnitDeploy  LemasPctOfficDrugUn  \\\n",
       "0                  0.0         5.561128e-16            -0.340751   \n",
       "1                  0.0         5.561128e-16            -0.340751   \n",
       "2                  0.0         5.561128e-16            -0.340751   \n",
       "3                  0.0         5.561128e-16            -0.340751   \n",
       "4                  0.0         5.561128e-16            -0.340751   \n",
       "\n",
       "   PolicBudgPerPop  assaultPerPop  \n",
       "0     3.647879e-16      -0.790188  \n",
       "1     3.647879e-16      -0.631690  \n",
       "2     3.647879e-16      -0.776613  \n",
       "3     3.647879e-16      -0.428234  \n",
       "4     3.647879e-16      -0.608593  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the StandardScaler class\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize Dataset\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the StandardScaler to the dataset\n",
    "norm_dataset = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
    "\n",
    "# Display the heads of the normalized dataset\n",
    "norm_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter methods\n",
    "\n",
    "### Colour Coded Correlation Matrix\n",
    "\n",
    "Using pandas defined .corr() function to calculate the correlation matrix of the numeric columns in the dataset. We are easily able to see the correlation between the features in the dataset. These are then plotted using matplotlib and seaborn to create a heatmap of the correlation matrix. This allows us to easily see the correlation between the features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.510378Z",
     "iopub.status.busy": "2024-11-12T11:27:44.509905Z",
     "iopub.status.idle": "2024-11-12T11:27:44.970170Z",
     "shell.execute_reply": "2024-11-12T11:27:44.969922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nplt.figure(figsize=(25, 20))\\nsns.heatmap(correlation_matrix, annot=False, cmap=\\'coolwarm\\', cbar=True)\\nplt.title(\"Correlation Matrix\")\\nplt.show()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the matplotlib and seaborn libraries\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "\n",
    "# Set the goal feature as the correlation target\n",
    "target = 'assaultPerPop'\n",
    "\n",
    "# Define the correlation matrix\n",
    "correlation_matrix = norm_dataset.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "\"\"\"\n",
    "plt.figure(figsize=(25, 20))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', cbar=True)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Selecting a Correlation Threshold\n",
    "\n",
    "When we calculated the correlation matrix, we found the index of mutual information between all the features. Now we will use this index to select the features that have are highly correlated with the target feature.\n",
    "\n",
    "1. Visually inspect the correlation matrix and select a threshold that makes sense based off the heatmap and the correlation values.\n",
    "\n",
    "2. Knowing the area/domain of the data and the features, select a threshold that makes sense. So if police where to look at the dataset they could identify the features that are highly correlated with each other and select a threshold that makes sense.\n",
    "\n",
    "3. Use common statistical thresholds, so between -1 and 1, a correlation of 0.7 is considered high, 0.5 is moderate and 0.3 is low. So you can select a threshold of 0.5 for example. These values have statistical significance and are commonly.\n",
    "\n",
    "4. Itersatively select a threshold and evaluate the model's performance. So you can start with a threshold of 0.5 and evaluate the model's performance, then increase or decrease the threshold and evaluate the model's performance again. This is a trial and error method but it is effective.\n",
    "\n",
    "\n",
    "Initially a common statistical threshold of 0.7 was chosen this is meant to be compared to absolute values so it acts as a -0.7 and a 0.7. This value was initially set.# Feature Selection Based on Correlation\n",
    "Select features based on a correlation threshold with the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.973216Z",
     "iopub.status.busy": "2024-11-12T11:27:44.972915Z",
     "iopub.status.idle": "2024-11-12T11:27:44.974346Z",
     "shell.execute_reply": "2024-11-12T11:27:44.974108Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select features based on a correlation threshold\n",
    "correlation_threshold = 0.5\n",
    "# Note a high index of 0.7 (for example) could not be used as there wouldn't be any dtypes left to select\n",
    "\n",
    "# Select the features based on the correlation absolute threshold value, that is taking both negative and positive scales\n",
    "selected_features = correlation_matrix.index[correlation_matrix[target].abs() > correlation_threshold].tolist()\n",
    "\n",
    "# Remove the target feature from the selected features\n",
    "selected_features.remove(target)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "#The dataset must now be split into training and testing subsets. It is critical that no data leakage occurs between the two subsets. The defined sklearn function train_test_split() ensures this.\n",
    "\n",
    "The decision of the split ratio is completely arbitrary and can be adjusted to ones liking. However, ideally you would want to have a larger training set than the test set. Common splits are 80/20 and 70/30. In this case, we will use an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.978975Z",
     "iopub.status.busy": "2024-11-12T11:27:44.978656Z",
     "iopub.status.idle": "2024-11-12T11:27:44.980173Z",
     "shell.execute_reply": "2024-11-12T11:27:44.979921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into train and test subsets\n",
    "train_ratio = 0.8\n",
    "df_train, df_test = train_test_split(norm_dataset, train_size=train_ratio, test_size=1-train_ratio)\n",
    "\n",
    "X_train = df_train[selected_features]\n",
    "y_train = df_train[target]\n",
    "X_test = df_test[selected_features]\n",
    "y_test = df_test[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Neural Network for Prediction\n",
    "\n",
    "The MLPRegressor is used as it is able to predict continuous values, unlike the MLPClassifier which predicts classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:44.982831Z",
     "iopub.status.busy": "2024-11-12T11:27:44.982357Z",
     "iopub.status.idle": "2024-11-12T11:27:47.484165Z",
     "shell.execute_reply": "2024-11-12T11:27:47.484627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the MLPRegressor class\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize the MLPRegressor with specified parameters\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "mlp_flt = mlp.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set after fitting the model\n",
    "y_pred = mlp_flt.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "\n",
    "The sklearn library provides a mean_squared_error function to compute the MSE between the actual and predicted values.\n",
    "\n",
    "The lower the MSE the better the model is performing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.487027Z",
     "iopub.status.busy": "2024-11-12T11:27:47.486282Z",
     "iopub.status.idle": "2024-11-12T11:27:47.491285Z",
     "shell.execute_reply": "2024-11-12T11:27:47.491839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error after feature selection:  0.6597754272045159\n"
     ]
    }
   ],
   "source": [
    "# Import the mean_squared_error function\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for the filter method\n",
    "mse_flt = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Print the Mean Squared Error\n",
    "print(\"Mean Squared Error after feature selection: \", mse_flt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Wrapper methods\n",
    "Implement Sequential Forward Selection (SFS) and Sequential Backward Selection (SBS) to obtain a maximum of 40 features in each case. Discuss the strengths and limitations of SFS and SBS in this context. Train a neural network using the selected features and compute the MSE on the test subset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Forward Selection (SFS)\n",
    "\n",
    "The SFS is a method of feature selection in which we start with an empty set of features and add features one by one. At each iteration, we analyze the performance of the model with the added feature and select the best feature based on a predefined criterion. The process continues until we tested all the features or reached a predefined number of features. The best number and combination of features are then selected based on the predefined criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.494272Z",
     "iopub.status.busy": "2024-11-12T11:27:47.493532Z",
     "iopub.status.idle": "2024-11-12T11:27:47.581161Z",
     "shell.execute_reply": "2024-11-12T11:27:47.580915Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054948/1748607241.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the SequentialFeatureSelector class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequentialFeatureSelector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the Sequential Forward Selection (SFS) object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sfs = SFS( mlp,\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "# Import the SequentialFeatureSelector class\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# Define the Sequential Forward Selection (SFS) object\n",
    "sfs = SFS( mlp,\n",
    "          k_features=min(40, X_train.shape[1]),\n",
    "          forward=True,\n",
    "          floating=False,\n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=5)\n",
    "\n",
    "# Fit the SFS object to the training data\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "sfs_features = list(sfs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Backward Selection (SBS)\n",
    "The SBS is similar to the SFS but in reverse order, it starts with all features and removes them one by one. At the end, it will return the best subset of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.583870Z",
     "iopub.status.busy": "2024-11-12T11:27:47.583395Z",
     "iopub.status.idle": "2024-11-12T11:27:47.588411Z",
     "shell.execute_reply": "2024-11-12T11:27:47.588029Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054948/3175473404.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import the SequentialBackwardSelector class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequentialFeatureSelector\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the Sequential Backward Selection (SBS) object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sbs = SBS(mlp, \n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "# Import the SequentialBackwardSelector class\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SBS\n",
    "\n",
    "# Define the Sequential Backward Selection (SBS) object\n",
    "sbs = SBS(mlp, \n",
    "          k_features=1, \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error', \n",
    "          cv=5)\n",
    "\n",
    "# Fit the SBS object to the training data\n",
    "sbs = sbs.fit(X_train, y_train)\n",
    "\n",
    "# Get the selected features\n",
    "sbs_features = list(sbs.k_feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on SFS and SBS\n",
    "\n",
    "\n",
    "**Simmilarities:**\n",
    "- Both SFS and SBS are easy to implement as they involve iterative feature selection with additional or removal of features.\n",
    "- They are both wrapper methods that use a predictive model to evaluate the feature subsets.\n",
    "- They both use greedy search strategies to select features which may lead to suboptimal solutions. This is they are unable to see the bigger picture and may not be optimal.\n",
    "\n",
    "**Strengths of SFS:**\n",
    "- SFS is computationally less expensive compared to exhaustive search methods.\n",
    "- It is useful when the number of features is large, as it incrementally adds features that improve the model.\n",
    "\n",
    "**Limitations of SFS:**\n",
    "- SFS can get stuck in local optima, as it does not consider removing features once added.\n",
    "- It may include redundant features that do not contribute significantly to the model's performance.\n",
    "\n",
    "**Strengths of SBS:**\n",
    "- SBS can remove irrelevant or redundant features, potentially leading to a more compact and interpretable model.\n",
    "- It can be useful when the initial feature set is large and contains many irrelevant features.\n",
    "\n",
    "**Limitations of SBS:**\n",
    "- SBS is computationally more expensive than SFS, as it starts with all features and removes them one by one.\n",
    "- It may remove features that are individually weak but collectively strong, leading to suboptimal feature subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Network with SFS Features\n",
    "After defining the SBS object, we now fit it to the training data and get the selected features. We then can calculate the Mean Squared Error (MSE) for the SBS selected features and compare it to the previous neural network results, that where selected based on the correlation threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.592780Z",
     "iopub.status.busy": "2024-11-12T11:27:47.592490Z",
     "iopub.status.idle": "2024-11-12T11:27:47.595558Z",
     "shell.execute_reply": "2024-11-12T11:27:47.595183Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sfs_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054948/2407141505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train a neural network using SFS selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp_sfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msfs_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_sfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_sfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msfs_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute the Mean Squared Error (MSE) for SFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sfs_features' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a neural network using SFS selected features\n",
    "mlp_sfs = mlp.fit(X_train[sfs_features], y_train)\n",
    "y_pred_sfs = mlp_sfs.predict(X_test[sfs_features])\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for SFS\n",
    "mse_sfs = mean_squared_error(y_test, y_pred_sfs)\n",
    "print(\"Mean Squared Error with SFS: \", mse_sfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Network with SBS Features\n",
    "Similary we now also fit the model with the selected features of the sbs and calculate the mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.600277Z",
     "iopub.status.busy": "2024-11-12T11:27:47.599807Z",
     "iopub.status.idle": "2024-11-12T11:27:47.602159Z",
     "shell.execute_reply": "2024-11-12T11:27:47.601787Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sbs_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054948/727242527.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train a neural network using SBS selected features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmlp_sbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msbs_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred_sbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp_sbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msbs_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Compute the Mean Squared Error (MSE) for SBS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sbs_features' is not defined"
     ]
    }
   ],
   "source": [
    "# Train a neural network using SBS selected features\n",
    "mlp_sbs = mlp.fit(X_train[sbs_features], y_train)\n",
    "y_pred_sbs = mlp_sbs.predict(X_test[sbs_features])\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for SBS\n",
    "mse_sbs = mean_squared_error(y_test, y_pred_sbs)\n",
    "print(\"Mean Squared Error with SBS: \", mse_sbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature projection\n",
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "PCA is a dimensionality reduction technique that can be used to reduce the number of features in a dataset by calculating the variance of each feature and selecting the most important ones. The higher the variance in a feature the more important it is to explain the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.605742Z",
     "iopub.status.busy": "2024-11-12T11:27:47.605401Z",
     "iopub.status.idle": "2024-11-12T11:27:47.797110Z",
     "shell.execute_reply": "2024-11-12T11:27:47.797339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the PCA class\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize a default PCA object\n",
    "pca = PCA()\n",
    "\n",
    "# Fit the PCA object on the training data\n",
    "pca.fit(X_train)\n",
    "\n",
    "# Plot the explained variance ratio to be able to select the number of components\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o', linestyle='--')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Explained Variance by Principal Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Cut-off Point\n",
    "After calculating variance and plotting the graph, we can now visualize a threshold based on how much variance we want to keep with the number of components\n",
    "\n",
    "### Comment on the choice\n",
    "\n",
    "The choice of threshold is important as it determines the number of components that will be selected. This was chosen to be 4 as it is the number of components that explain close to 95% of the variance, which captures a significant amount of the variance in the data. After this point, the slope of the curve flattens, which means that the variance explained by each additional component is not as significant as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.799810Z",
     "iopub.status.busy": "2024-11-12T11:27:47.799405Z",
     "iopub.status.idle": "2024-11-12T11:27:47.801434Z",
     "shell.execute_reply": "2024-11-12T11:27:47.801183Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Select the threshold for component selection\n",
    "component_threshold = 4\n",
    "\n",
    "# Assign the selected components to a specific PCA object\n",
    "pca = PCA(n_components=component_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on PCA\n",
    "\n",
    "**Strengths of PCA:**\n",
    "- PCA reduces the dimensionality of the dataset, which can lead to faster training times and reduced computational cost.\n",
    "- It can help to remove noise and redundant features, potentially improving model performance.\n",
    "- PCA can reveal the underlying structure of the data by identifying the principal components that explain the most variance.\n",
    "\n",
    "**Limitations of PCA:**\n",
    "- PCA is a linear method and may not capture complex, non-linear relationships in the data.\n",
    "- The principal components may not have a clear interpretation, making it difficult to understand the impact of individual features.\n",
    "- PCA requires the data to be standardized, which may not always be appropriate for all datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Neural Network with PCA Features\n",
    "\n",
    "We can now transform and fit the training data, aswell as transform the test data. So that we can test the effectiveness of the PCA feature selection based on variance through a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:47.805129Z",
     "iopub.status.busy": "2024-11-12T11:27:47.804519Z",
     "iopub.status.idle": "2024-11-12T11:27:49.084230Z",
     "shell.execute_reply": "2024-11-12T11:27:49.084491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with PCA:  0.6328206940392391\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Fit and transform the training data \n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train a neural network using PCA selected features\n",
    "mlp_pca = mlp.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test set after fitting the model with PCA\n",
    "y_pred_pca = mlp_pca.predict(X_test_pca)\n",
    "\n",
    "# Compute the Mean Squared Error (MSE) for PCA\n",
    "mse_pca = mean_squared_error(y_test, y_pred_pca)\n",
    "print(\"Mean Squared Error with PCA: \", mse_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Comparison\n",
    "Compare the MSE for the four methods used (filter, SFS, SBS, PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T11:27:49.086654Z",
     "iopub.status.busy": "2024-11-12T11:27:49.085908Z",
     "iopub.status.idle": "2024-11-12T11:27:49.097340Z",
     "shell.execute_reply": "2024-11-12T11:27:49.097881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error with Filter Method:  0.6597754272045159\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mse_sfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2054948/3320068714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print the mse for all the methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error with Filter Method: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_flt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error with SFS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_sfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error with SBS: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_sbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean Squared Error with PCA: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mse_sfs' is not defined"
     ]
    }
   ],
   "source": [
    "# Print the mse for all the methods\n",
    "print(\"Mean Squared Error with Filter Method: \", mse_flt)\n",
    "print(\"Mean Squared Error with SFS: \", mse_sfs)\n",
    "print(\"Mean Squared Error with SBS: \", mse_sbs)\n",
    "print(\"Mean Squared Error with PCA: \", mse_pca)\n",
    "\n",
    "# Plot the mse for comparison in a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(['Filter Method', 'SFS', 'SBS', 'PCA'], [mse_flt, mse_sfs, mse_sbs, mse_pca])\n",
    "plt.xlabel('Feature Selection Method')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Mean Squared Error by Feature Selection Method')\n",
    "# Zoom in due to the small differences\\\n",
    "plt.ylim(0.4,0.55)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discus Methods\n",
    "PCA showed the best results for this dataset as it had the lowest MSE. It was able to reduce the dimensionality of the dataset while still maintaining the predictive power of the model. Second best was the SBS method, it proved better than SFS in this case and this could be due to the nature of the dataset. The wrapper methods (SFS and SBS) are computationally expensive compared to the filter methods and PCA. The filter method was the least effective in this case as it does not consider the relationship between features and the target variable. But rather it is based on the correlation between features and this could lead to the selection of irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plagerism \n",
    "\n",
    "- Use of ChatGPT and Co-Pilot moslty for plot parameters and syntax. However failed to use the sklearn libaries properly.property\n",
    "\n",
    "- Sklearn documentation was used to understand the parameters and functions being used. \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SequentialFeatureSelector.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cce3503-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
